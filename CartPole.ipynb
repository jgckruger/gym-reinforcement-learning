{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent():\n",
    "    def __init__(self, env):\n",
    "        self.action_size = env.action_space.n\n",
    "        print('Action space size: ', self.action_size)\n",
    "    \n",
    "    def get_action(self, observation):\n",
    "        action = random.choice(range(self.action_size))\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralRandomAgent():\n",
    "    def __init__(self, env):\n",
    "        self.is_discrete = type(env.action_space) == gym.spaces.discrete.Discrete\n",
    "        \n",
    "        if self.is_discrete:\n",
    "            self.action_size = env.action_space.n\n",
    "            print('Action space size: ', self.action_size)\n",
    "        else: \n",
    "            self.action_low = env.action_space.low\n",
    "            self.action_high = env.action_space.high\n",
    "            self.action_shape = env.action_space.shape\n",
    "            print('Action range: ', self.action_low, self.action_high)\n",
    "    \n",
    "    def get_action(self, observation):\n",
    "        if self.is_discrete:\n",
    "            action = random.choice(range(self.action_size))\n",
    "        else:\n",
    "            action = np.random.uniform(self.action_low, self.action_high, self.action_shape)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleReflexAgent():\n",
    "    def __init__(self, env):\n",
    "        self.action_size = env.action_space.n\n",
    "        print('Action space size: ', self.action_size)\n",
    "    \n",
    "    def get_action(self, observation):\n",
    "        angle = observation[2]\n",
    "        \n",
    "        if angle < 0:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = 1 \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space:  Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n",
      "Action space:  Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "# http://gym.openai.com/envs/CartPole-v1/\n",
    "env = gym.make('CartPole-v0')\n",
    "print('Observation space: ', env.observation_space)\n",
    "print('Action space: ', env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space size:  2\n",
      "Episode finished after 70 timesteps\n",
      "Episode finished after 44 timesteps\n",
      "Episode finished after 19 timesteps\n",
      "Episode finished after 30 timesteps\n",
      "Episode finished after 13 timesteps\n",
      "Episode finished after 35 timesteps\n",
      "Episode finished after 49 timesteps\n",
      "Episode finished after 9 timesteps\n",
      "Episode finished after 18 timesteps\n",
      "Episode finished after 36 timesteps\n",
      "Episode finished after 16 timesteps\n",
      "Episode finished after 26 timesteps\n",
      "Episode finished after 37 timesteps\n",
      "Episode finished after 13 timesteps\n",
      "Episode finished after 17 timesteps\n"
     ]
    }
   ],
   "source": [
    "# Random agent\n",
    "number_of_episodes = 15\n",
    "number_of_steps = 200\n",
    "observation = env.reset()\n",
    "agent = GeneralRandomAgent(env)\n",
    "for episode in range(number_of_episodes):\n",
    "    observation = env.reset()\n",
    "    for t in range(number_of_steps):\n",
    "        env.render()\n",
    "        action = agent.get_action(observation)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space size:  2\n",
      "Episode finished after 52 timesteps\n",
      "Episode finished after 52 timesteps\n",
      "Episode finished after 49 timesteps\n",
      "Episode finished after 45 timesteps\n",
      "Episode finished after 48 timesteps\n"
     ]
    }
   ],
   "source": [
    "# Simple reflex agent\n",
    "number_of_episodes = 5\n",
    "number_of_steps = 200\n",
    "observation = env.reset()\n",
    "agent = SimpleReflexAgent(env)\n",
    "for episode in range(number_of_episodes):\n",
    "    observation = env.reset()\n",
    "    for t in range(number_of_steps):\n",
    "        env.render()\n",
    "        action = agent.get_action(observation)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
